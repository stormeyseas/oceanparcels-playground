{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a001ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "%matplotlib inline\n",
    "import parcels\n",
    "from parcels import FieldSet, ParticleSet, JITParticle, AdvectionRK4_3D, AdvectionRK4, ParticleFile, ErrorCode, Variable, VectorField, Field, FieldSamplingError, plotTrajectoriesFile, GeographicPolar, Geographic, logger\n",
    "from parcels import TimeConverter, ScipyParticle\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import math\n",
    "from math import sqrt\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt, animation\n",
    "import datetime as dati\n",
    "import time as tm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def GeneralStats(array):\n",
    "    stats = np.nanmean(array), np.nanstd(array), np.nanmin(array), np.nanmax(array)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496cc087",
   "metadata": {},
   "source": [
    "## Files and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dc30604",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\\\OceanParcels\" # for working on home computer\n",
    "\n",
    "month = np.array([\"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\"])\n",
    "coordfile = path + \"\\\\data\\\\processed\\\\coordinates.nc\"\n",
    "\n",
    "gr_raw = path + \"\\\\data\\\\raw\\\\reindexed_\" # reindexed raw grid data\n",
    "gr_int = path + \"\\\\data\\\\processed\\\\interim grids\\\\reindexed_\"\n",
    "gr_fin = path + \"\\\\data\\\\processed\\\\final grids\\\\final_\" # final grids\n",
    "sm_path = path + \"\\\\data\\\\processed\\\\summary stats\\\\\"\n",
    "sc_path = path + \"\\\\data\\\\processed\\\\scenario data\\\\\"\n",
    "densitydata = path + \"\\\\data\\\\raw\\\\year_D2.csv\"\n",
    "\n",
    "scenario = np.array([\"S0\", \"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\"])\n",
    "days = np.array([31, 30, 31, 31, 30, 31])\n",
    "cday = np.array([1, 32, 62, 93, 124, 154])\n",
    "\n",
    "canopy_range = range(4,10)\n",
    "under_range = range(11,21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4ad832",
   "metadata": {},
   "source": [
    "# Average velocity\n",
    "\n",
    "Calculate and save average velocity (unattenuated) for each month. This outputs a 3D (depth-averagd) array of lat, lon, and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6d53a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped!\n"
     ]
    }
   ],
   "source": [
    "%%script echo Skipped!\n",
    "\n",
    "for mo in range(0,6):\n",
    "    print(\"Starting \" + month[mo] + \"...\")\n",
    "    \n",
    "    # Open file\n",
    "    ds = xr.open_dataset(gr_raw + month[mo] + \".nc\").load()    \n",
    "    # Simple variables\n",
    "    Uav = ds.Uav.values\n",
    "    Vav = ds.Vav.values\n",
    "    tt = sum(np.shape(ds.t.values))\n",
    "    ds.close()\n",
    "    \n",
    "    UVbar = np.sqrt(np.power(Uav,2) + np.power(Vav,2))\n",
    "    dsUVbar = xr.DataArray(data = UVbar.astype('float32'), name = \"UVbar\", dims = ['t', 'j', 'i'])\n",
    "\n",
    "    ds = ds.merge(dsUVbar).drop_vars(['U', 'V', 'W'])\n",
    "\n",
    "    ds.to_netcdf(gr_int + month[mo] + \"_2D.nc\")\n",
    "    print(\"New grid saved to NetCDF\")\n",
    "\n",
    "    # Depth-averaged velocity\n",
    "    UVbarstats = np.zeros(shape = (tt, 4))\n",
    "\n",
    "    for ti in range(tt):\n",
    "        UVbarstats[ti, :] = GeneralStats(UVbar[ti, :, :])\n",
    "\n",
    "    UVbarstats = pd.DataFrame(UVbarstats)\n",
    "    UVbarstats.to_csv(sm_path + \"UVbar_stats_\" + month[mo] + \".csv\", index = False)\n",
    "\n",
    "    del UVbarstats, UVbar, dsUVbar, Uav, Vav, tt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9342d399",
   "metadata": {},
   "source": [
    "# Load and save density scenario data\n",
    "\n",
    "The numpys are saved so that they can be generated in one big go and called later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95a55d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped!\n"
     ]
    }
   ],
   "source": [
    "%%script echo Skipped!\n",
    "\n",
    "# Load macroalgae density data\n",
    "D0 = np.genfromtxt(densitydata, delimiter = ',')[1:186,3]\n",
    "\n",
    "for mo in range(0,6):\n",
    "    ds = xr.open_dataset(gr_raw + month[mo] + \".nc\").load()\n",
    "    tt = sum(np.shape(ds.t.values))\n",
    "    ii = sum(np.shape(ds.i.values))\n",
    "    jj = sum(np.shape(ds.j.values))\n",
    "    kk = sum(np.shape(ds.k.values))\n",
    "    ds.close()\n",
    "    del ds\n",
    "    \n",
    "    # Current Dx and Dy\n",
    "    Dx = np.linspace(1, days[mo], days[mo])\n",
    "    Dy = D0[cday[mo]:(cday[mo]+days[mo])]\n",
    "    \n",
    "    # New Dx and Dy\n",
    "    Dx1 = np.linspace(1, days[mo], tt)\n",
    "    Dy1 = np.interp(Dx1, Dx, Dy)\n",
    "    \n",
    "    # Extend D to correct dimensions\n",
    "    Dy1 = np.repeat(Dy1[:, np.newaxis], jj, axis = 1)\n",
    "    Dy1 = np.repeat(Dy1[:, :, np.newaxis], ii, axis = 2)\n",
    "    Dy1 = np.repeat(Dy1[:, np.newaxis, :, :], kk, axis = 1)\n",
    "    \n",
    "    # Save one empty scenario\n",
    "    D2 = np.zeros([tt, kk, jj, ii])\n",
    "    np.save(sc_path + \"D_\" + month[mo] + \"_S0.npy\", D2.astype('float32'))\n",
    "    del D2\n",
    "    \n",
    "    # For each scenario\n",
    "    for sc in range(1, 7):\n",
    "        sc_c = np.load(sc_path + scenario[sc] + \".npy\")\n",
    "        sc_c = np.repeat(sc_c[None, :, :], tt, axis = 0)\n",
    "\n",
    "        sc_c_1 = np.repeat(sc_c[:, None, :, :], 7, axis = 1)  # canopy spans depth layers 4-10 inclusive\n",
    "        sc_c = np.concatenate((np.zeros([tt, 4, jj, ii]), sc_c_1, np.zeros([tt, (kk-4-7), jj, ii])), axis = 1)\n",
    "        \n",
    "        D3 = Dy1 * sc_c\n",
    "        np.save(sc_path + \"D_\" + month[mo] + \"_\" + scenario[sc] + \".npy\", D3.astype('float32'))\n",
    "        \n",
    "        print(\"Density data shaped and saved for \" + month[mo] + \", \" + scenario[sc])\n",
    "        del sc_c, D3, sc_c_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda9e7f7",
   "metadata": {},
   "source": [
    "# Calculate attenuation\n",
    "\n",
    "Attenuation changes with time and kelp density (D), depth-averaged velocity (UV-bar), depth (within or beneath canopy) and total water depth (botz). \n",
    "\n",
    "Technically this is a little bit of a stretch, as Plew's attenuation equation is only intended to come up with a total depth-averaged drag coefficient (Ct) which is a combination of u_c and u_b, and it's not meant to be literally applied to the within-canopy and beneath-canopy velocities seperately. However, it does give relative attenuation coefficients that are very reasonable when compared to actual data, so a case can be made that it's a good enough approximation. I think I can swing it alright if I focus on the big picture, or if it ends up being too iffy I can just run the model in 2D model and depth-average everything - I'll lose a little nuance but that's OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f4f742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped!\n"
     ]
    }
   ],
   "source": [
    "%%script echo Skipped!\n",
    "aa = pow(0.2,2)\n",
    "Cb = 0.0025\n",
    "\n",
    "dscoords = xr.open_dataset(coordfile, decode_times = False).load()\n",
    "botz = dscoords.botz.values\n",
    "dscoords.close()\n",
    "del dscoords\n",
    "\n",
    "for mo in range(0,6):\n",
    "    print(\"Starting \" + month[mo] + \"...\")\n",
    "\n",
    "    ds3D = xr.open_dataset(gr_raw + month[mo] + \".nc\", decode_times = False).load()\n",
    "    kk = sum(np.shape(ds3D.k.values))\n",
    "    ds3D.close()\n",
    "    \n",
    "    ds2D = xr.open_dataset(gr_int + month[mo] + \"_2D.nc\", decode_times = False).load()\n",
    "    UVbar = ds2D.UVbar.values\n",
    "    tt = sum(np.shape(ds2D.t.values))\n",
    "    ii = sum(np.shape(ds2D.i.values))\n",
    "    jj = sum(np.shape(ds2D.j.values))\n",
    "    ds2D.close()\n",
    "\n",
    "    for sc in range(0,7):\n",
    "        print(\"Starting scenario \" + scenario[sc] + \"...\")\n",
    "        \n",
    "        uc_ub = np.ones(shape = (tt, kk, jj, ii))\n",
    "        Ct = np.zeros(shape = (tt, jj, ii))\n",
    "        \n",
    "        D_c = np.load(sc_path + \"D_\" + month[mo] + \"_\" + scenario[sc] + \".npy\")\n",
    "        \n",
    "        count = 0\n",
    "        milcount = 0\n",
    "        \n",
    "        for xi in range(ii):  \n",
    "            for yi in range(jj):    \n",
    "                wz = abs(botz[yi, xi])\n",
    "                H = 6.4/wz\n",
    "                for ti in range(tt):  \n",
    "                    D = D_c[ti, 7, yi, xi] # canopy density\n",
    "                    UV0 = UVbar[ti, yi, xi]\n",
    "                    Kd = 0.5 * wz * D * 0.0045 * pow(UV0,(1.13-2)) # D already includes the extra 0.5\n",
    "                    under = Kd*H*(1-H)*(Cb*H+aa)-(aa*Cb*H)\n",
    "                    if under < 0:\n",
    "                        uc = 1\n",
    "                        ub = 1\n",
    "                    else:\n",
    "                        top = -aa-Cb*pow(H,2)+(1-H)*sqrt(under)\n",
    "                        bot = Kd*H*pow((1-H),3)-aa-Cb*pow(H,3)\n",
    "                        uc = top/bot\n",
    "                        ub = (1-uc*H)/(1-H)\n",
    "                    Ct[ti, yi, xi] = Kd*H*pow(uc,2) + Cb*pow(ub,2)\n",
    "                    \n",
    "                    for zi in range(kk): # Attenuation is depth-averaged but, seperated between canopy and under-canopy\n",
    "                        if zi in canopy_range:\n",
    "                            uc_ub[ti, zi, yi, xi] = uc\n",
    "                        else:\n",
    "                            uc_ub[ti, zi, yi, xi] = ub\n",
    "                        \n",
    "                        count += 1\n",
    "                        if count == 10e6:\n",
    "                            milcount += 10\n",
    "                            print(milcount, \" of \", round(tt*ii*jj*kk/1e6,2), \" million cells processed\")\n",
    "                            count = 0\n",
    "                    \n",
    "        print(\"Attenuation for \" + scenario[sc] + \" calculated\")\n",
    "        \n",
    "        ds_uc_ub = xr.DataArray(data = uc_ub.astype('float32'), name = \"uc_ub\", dims = ['t', 'k', 'j', 'i'])\n",
    "        ds_uc_ub = ds3D.merge(ds_uc_ub)\n",
    "        ds_uc_ub.to_netcdf(gr_int + month[mo] + \"_\" + scenario[sc] + \"_3D.nc\")\n",
    "\n",
    "        ds_Ct = xr.DataArray(data = Ct.astype('float32'), name = \"Ctbar\", dims = ['t', 'j', 'i'])\n",
    "        ds_Ct = ds2D.merge(ds_Ct)\n",
    "        ds_Ct.to_netcdf(gr_int + month[mo] + \"_\" + scenario[sc] + \"_2D.nc\")\n",
    "        \n",
    "        print(\"Scenario \" + scenario[sc] + \" datasets created and saved\")\n",
    "        del ds_Ct, ds_uc_ub\n",
    "        \n",
    "        attenUV = uc_ub\n",
    "        attenUV[attenUV == 1] = None\n",
    "        Ct[Ct == 0.0025] = None\n",
    "        \n",
    "        # Attenuation and drag coefficient for each time mean (all lon+lat), sd, min, max\n",
    "        uc_stats = np.zeros(shape = (tt, 4))\n",
    "        ub_stats = np.zeros(shape = (tt, 4))\n",
    "        Ct_stats = np.zeros(shape = (tt, 4))\n",
    "        \n",
    "        for ti in range(tt):\n",
    "            uc_stats[ti, :] = GeneralStats(attenUV[ti, canopy_range, :, :])\n",
    "            ub_stats[ti, :] = GeneralStats(attenUV[ti, under_range, :, :])\n",
    "            Ct_stats[ti, :] = GeneralStats(Ct[ti, :, :])\n",
    "\n",
    "        uc_stats = pd.DataFrame(uc_stats)\n",
    "        uc_stats.to_csv(sm_path + \"uc_stats_\" + month[mo] + \"_\" + scenario[sc] + \".csv\", index = False)\n",
    "        \n",
    "        ub_stats = pd.DataFrame(ub_stats)\n",
    "        ub_stats.to_csv(sm_path + \"ub_stats_\" + month[mo] + \"_\" + scenario[sc] + \".csv\", index = False)\n",
    "        \n",
    "        Ct_stats = pd.DataFrame(Ct_stats)\n",
    "        Ct_stats.to_csv(sm_path + \"Ct_stats_\" + month[mo] + \"_\" + scenario[sc] + \".csv\", index = False)\n",
    "\n",
    "        del Ct, Ct_stats, uc_stats, ub_stats, attenUV, uc_ub\n",
    "        print(\"Scenario \" + scenario[sc] + \" stats finished\")\n",
    "        \n",
    "del ds3D, ds2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92705a63",
   "metadata": {},
   "source": [
    "# Convert depth-averaged attenuation to component attenuation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae95c25",
   "metadata": {},
   "source": [
    "Need to calculate the attenuation component $u_c'$, so that the attenuated velocity components $U_c=U*u_c'$ and $V_c=V*u_c'$ add up to the depth-averaged attenuation: $u_c'=\\frac{\\overline{UV_c}}{\\sqrt{U^2+V^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dd14f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped!\n"
     ]
    }
   ],
   "source": [
    "%%script echo Skipped!\n",
    "# atten = depth-averaged attenuation (either u_c or u_b)\n",
    "# comp = attenuation component (for U and V)\n",
    "# att_c = array of comp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "for mo in range(1,6):\n",
    "    for sc in range(0,7):\n",
    "        print(\"Starting \" + month[mo] + \", \" + scenario[sc] + \"...\")\n",
    "        # Load component velocities\n",
    "        ds3D = xr.open_dataset(gr_int + month[mo] + \"_\" + scenario[sc] + \"_3D.nc\", decode_times = False).load()\n",
    "        U = ds3D.U.values\n",
    "        V = ds3D.V.values\n",
    "        uc_ub = ds3D.uc_ub.values.astype('float32')\n",
    "        tt = sum(np.shape(ds3D.t.values))\n",
    "        ii = sum(np.shape(ds3D.i.values))\n",
    "        jj = sum(np.shape(ds3D.j.values))\n",
    "        kk = sum(np.shape(ds3D.k.values))\n",
    "        ds3D.close()\n",
    "        \n",
    "        # Load depth-averaged velocity and attenuation (UV bar is identical for every scenario)\n",
    "        ds2D = xr.open_dataset(gr_int + month[mo] + \"_\" + scenario[sc] + \"_2D.nc\", decode_times = False).load()\n",
    "        UVbar = ds2D.UVbar.values.astype('float32')\n",
    "        Uav = ds2D.Uav.values.astype('float32')\n",
    "        Vav = ds2D.Vav.values.astype('float32')\n",
    "        ds2D = ds2D.drop_vars(['Uav', 'Vav'])\n",
    "        ds2D.close()\n",
    "        \n",
    "        UVbar_z = np.repeat(UVbar[:, np.newaxis, :, :], repeats = kk, axis = 1)\n",
    "\n",
    "        UVbar_atten = np.zeros(shape = (tt, kk, jj, ii)).astype('float32')\n",
    "        att_c = np.ones(shape = (tt, kk, jj, ii)).astype('float32')\n",
    "        V_atten = np.zeros(shape = (tt, kk, jj, ii)).astype('float32')\n",
    "        U_atten = np.zeros(shape = (tt, kk, jj, ii)).astype('float32')\n",
    "        \n",
    "        count = 0\n",
    "        milcount = 0\n",
    "        \n",
    "        for xi in range(ii):  \n",
    "            for yi in range(jj):    \n",
    "                for ti in range(tt):        \n",
    "                    for zi in range(kk):\n",
    "                        if zi in canopy_range:\n",
    "                            atten = uc_ub[ti, zi, yi, xi]\n",
    "                        else:\n",
    "                            atten = uc_ub[ti, zi, yi, xi]\n",
    "                        \n",
    "                        # Apply depth-averaged attenuation to depth-averaged velocity\n",
    "                        UVbar_atten[ti, zi, yi, xi] = UVbar_z[ti, zi, yi, xi] * atten\n",
    "                        \n",
    "                        if atten == 1:\n",
    "                            comp = 1\n",
    "                        else: # Calculate component velocities\n",
    "                            try:\n",
    "                                comp = UVbar_atten[ti, zi, yi, xi]/(sqrt(pow(Uav[ti, yi, xi],2) + pow(Vav[ti, yi, xi],2)))\n",
    "                            except RuntimeWarning:\n",
    "                                if Uav[ti, yi, xi] != 0 and Vav[ti, yi, xi] != 0:\n",
    "                                    print(\"Divide by zero error at t=%f, k=%f, j=%f, i=%f, with UVbar=%f, U=%f, V=%f\" \n",
    "                                          %(round(ti), round(zi), round(yi), round(xi), UVbar_atten[ti, zi, yi, xi], U[ti, zi, yi, xi], V[ti, zi, yi, xi]))\n",
    "                                    break\n",
    "                                else:\n",
    "                                    comp = 1\n",
    "                        \n",
    "                        V_atten[ti, zi, yi, xi] = V[ti, zi, yi, xi] * comp\n",
    "                        U_atten[ti, zi, yi, xi] = U[ti, zi, yi, xi] * comp\n",
    "                        att_c[ti, zi, yi, xi] = comp\n",
    "                        \n",
    "                        count += 1\n",
    "                        if count == 10e6:\n",
    "                            milcount += 10\n",
    "                            print(milcount, \" of \", round(tt*ii*jj*kk/1e6,2), \" million cells processed\")\n",
    "                            count = 0\n",
    "        \n",
    "        dsatten = xr.Dataset(\n",
    "            data_vars = {'V_atten': (['t','k','j','i'], V_atten.astype('float32')),\n",
    "                         'U_atten': (['t','k','j','i'], U_atten.astype('float32')),\n",
    "                         'att_c': (['t','k','j','i'], att_c.astype('float32'))\n",
    "                        })\n",
    "        dsfin = ds2D.merge(dsatten)\n",
    "        dsfin = ds3D.merge(dsfin)\n",
    "        dsfin.to_netcdf(gr_fin + month[mo] + \"_\" + scenario[sc] + \".nc\")\n",
    "\n",
    "dsfin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41759906",
   "metadata": {},
   "source": [
    "## Fix times in the final grids\n",
    "\n",
    "Not sure if this is even necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64d24c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scenario  S0 ...\n",
      "May saved sucessfully\n",
      "June saved sucessfully\n",
      "July saved sucessfully\n",
      "August saved sucessfully\n",
      "September saved sucessfully\n",
      "October saved sucessfully\n",
      "Starting scenario  S1 ...\n",
      "May saved sucessfully\n",
      "June saved sucessfully\n",
      "July saved sucessfully\n",
      "August saved sucessfully\n",
      "September saved sucessfully\n",
      "October saved sucessfully\n",
      "Starting scenario  S2 ...\n",
      "May saved sucessfully\n",
      "June saved sucessfully\n",
      "July saved sucessfully\n",
      "August saved sucessfully\n",
      "September saved sucessfully\n",
      "October saved sucessfully\n",
      "Starting scenario  S3 ...\n",
      "May saved sucessfully\n",
      "June saved sucessfully\n",
      "July saved sucessfully\n",
      "August saved sucessfully\n",
      "September saved sucessfully\n",
      "October saved sucessfully\n",
      "Starting scenario  S4 ...\n",
      "May saved sucessfully\n",
      "June saved sucessfully\n",
      "July saved sucessfully\n",
      "August saved sucessfully\n",
      "September saved sucessfully\n",
      "October saved sucessfully\n",
      "Starting scenario  S5 ...\n",
      "May saved sucessfully\n",
      "June saved sucessfully\n",
      "July saved sucessfully\n",
      "August saved sucessfully\n",
      "September saved sucessfully\n",
      "October saved sucessfully\n",
      "Starting scenario  S6 ...\n",
      "May saved sucessfully\n",
      "June saved sucessfully\n",
      "July saved sucessfully\n",
      "August saved sucessfully\n",
      "September saved sucessfully\n",
      "October saved sucessfully\n"
     ]
    }
   ],
   "source": [
    "#%%script echo Skipped!\n",
    "times_may = np.linspace(start = 0, num = 4464, \n",
    "                        stop = dati.timedelta(days = 30, hours = 23, minutes = 50).total_seconds())\n",
    "times_jun = np.linspace(start = times_may[-1] + dati.timedelta(minutes = 10).total_seconds(), num = 4320, \n",
    "                        stop = times_may[-1] + dati.timedelta(days = 30).total_seconds())\n",
    "times_jul = np.linspace(start = times_jun[-1] + dati.timedelta(minutes = 10).total_seconds(), num = 4464, \n",
    "                        stop = times_jun[-1] + dati.timedelta(days = 31).total_seconds())\n",
    "times_aug = np.linspace(start = times_jul[-1] + dati.timedelta(minutes = 10).total_seconds(), num = 4464, \n",
    "                        stop = times_jul[-1] + dati.timedelta(days = 31).total_seconds())\n",
    "times_sep = np.linspace(start = times_aug[-1] + dati.timedelta(minutes = 10).total_seconds(), num = 4320, \n",
    "                        stop = times_aug[-1] + dati.timedelta(days = 30).total_seconds())\n",
    "times_oct = np.linspace(start = times_sep[-1] + dati.timedelta(minutes = 10).total_seconds(), num = 4464, \n",
    "                        stop = times_sep[-1] + dati.timedelta(days = 31).total_seconds())\n",
    "\n",
    "for sc in range(7):\n",
    "    print(\"Starting scenario \", scenario[sc], \"...\")\n",
    "    \n",
    "    ds = xr.open_dataset(gr_fin + month[0] + \"_\" + scenario[sc] + \".nc\", decode_times = False).load()\n",
    "    ds.close()\n",
    "    ds.times_secs.values = times_may\n",
    "    ds.to_netcdf(gr_fin + month[0] + \"_\" + scenario[sc] + \"_1.nc\")\n",
    "    print(\"May saved sucessfully\")\n",
    "\n",
    "    ds = xr.open_dataset(gr_fin + month[1] + \"_\" + scenario[sc] + \".nc\", decode_times = False).load()\n",
    "    ds.close()\n",
    "    ds.times_secs.values = times_jun\n",
    "    ds.to_netcdf(gr_fin + month[1] + \"_\" + scenario[sc] + \"_1.nc\")\n",
    "    print(\"June saved sucessfully\")\n",
    "\n",
    "    ds = xr.open_dataset(gr_fin + month[2] + \"_\" + scenario[sc] + \".nc\", decode_times = False).load()\n",
    "    ds.close()\n",
    "    ds.times_secs.values = times_jul\n",
    "    ds.to_netcdf(gr_fin + month[2] + \"_\" + scenario[sc] + \"_1.nc\")\n",
    "    print(\"July saved sucessfully\")\n",
    "\n",
    "    ds = xr.open_dataset(gr_fin + month[3] + \"_\" + scenario[sc] + \".nc\", decode_times = False).load()\n",
    "    ds.close()\n",
    "    ds.times_secs.values = times_aug\n",
    "    ds.to_netcdf(gr_fin + month[3] + \"_\" + scenario[sc] + \"_1.nc\")\n",
    "    print(\"August saved sucessfully\")\n",
    "\n",
    "    ds = xr.open_dataset(gr_fin + month[4] + \"_\" + scenario[sc] + \".nc\", decode_times = False).load()\n",
    "    ds.close()\n",
    "    ds.times_secs.values = times_sep\n",
    "    ds.to_netcdf(gr_fin + month[4] + \"_\" + scenario[sc] + \"_1.nc\")\n",
    "    print(\"September saved sucessfully\")\n",
    "    \n",
    "    ds = xr.open_dataset(gr_fin + month[5] + \"_\" + scenario[sc] + \".nc\", decode_times = False).load()\n",
    "    ds.close()\n",
    "    ds.times_secs.values = times_oct\n",
    "    ds.to_netcdf(gr_fin + month[5] + \"_\" + scenario[sc] + \"_1.nc\")\n",
    "    print(\"October saved sucessfully\")\n",
    "\n",
    "del ds, times_may, times_jun, times_jul, times_aug, times_sep, times_oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add50396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
